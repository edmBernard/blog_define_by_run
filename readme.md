# Define by run (Dynamic network)


commentary on github :
why gluon and not keras 2 ?

## noob point of view

debugging
not visible on small network 
example mxnet vs gluon

## modular network

easy to combine network
more flexibility 
easier to create complexe architecture (network in concurence)

## no hidden thing

as imperative the network do what you want and what you tell it. 
not inside compilation exemple shared weight.

that was more framework agnostic 
exemple between pytorch and gluon for shared weight


