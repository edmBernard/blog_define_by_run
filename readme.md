# Define by run (Dynamic network)

as a new deeplearning user why imperative framework it seem identical on tutorial but more example bigger community quick answer etc ...

commentary on github :
why gluon and not keras 2 ?

## noob point of view

debugging
not visible on small network 
example mxnet vs gluon

## modular network

easy to combine network
more flexibility 
easier to create complexe architecture (network in concurence)

## no hidden thing

as imperative the network do what you want and what you tell it. 
not inside compilation exemple shared weight.

that was more framework agnostic 
like normal python/numpy normal for loop if while etc ...
exemple between pytorch and gluon for shared weight


